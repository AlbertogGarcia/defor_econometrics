---
title: "outline_sep19"
author: "Alberto Garcia"
date: "September 3, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source('quickmontey.R')
source('binary_coeffdist_fcn.R')
source('funcform.R')
source('grid_scapegen.R')
source('grid_sim.R')
source('property_scapegen.R')
source('weightedreg_test.R')
source('property_perturb.R')
source('outcome_comparison.R')

```

Define universal parameters
```{r parameters}
b0 = .05
b1 = -0.1
b2 = -0.2
b3 = .16
std_a = .1
std_v = 0.25
years = 3
nobs = 10000
n = 100


cellsize = 20
ppoints = 200
std_p = .2

cpoints = 20
```



```{r DIDy, results='hide'}
DID_y <- quickmontey(n, nobs, years, b0, b1, b2, b3, std_a, std_v, "y")
DID_y$plot
```

Above, we see a slight bias in the DID estimates of the ATT when the binary outcome is able to vary between 0 and 1 across periods. This comes from the DID estimand not identifying the ATT with the DGP. 




```{r DIDy_it, results='hide'}
DID_yit <- quickmontey(n, nobs, years, b0, b1, b2, b3, std_a, std_v, "y_it")
DID_yit$plot
```

In the above plot, we drop pixels in the periods after they first become deforested. The DID estimates are still biased here. It appears that neither the sign nor magnitude of the bias seems to change. 


```{r FE, results='hide'}
twowayFE <- binary_coeffdist_fcn(n, nobs, years, b0, b1, b2, b3, std_a, std_v)
twowayFE$plot
```

Above, we address the use of two-way fixed effects and the dropping of observations in the periods after pixels are first observed as deforested. The magnitude of the bias is smallest using the basic DID. The bias is negative when using the 2way FE dropping deforested obs and when using either the DID or 2way FE keeping obs. Note that the DID and 2way fixed effects estimates are identical when observations are not dropped. As we show in our proof, in the general case, using 2 way fixed effects dropping the observations yields the ATT plus the difference between the treated and untreated groups. The DID on the other hand should identify the ATT. 




```{r functionalforms, results='hide'}
functionalform <- funcform(n, nobs, years, b0, b1, b2, b3, std_a, std_v)
functionalform$plot
```

The above plot shows the DID bias depending on functional form decisions. Interestingly in our case, the magnitude of the bias is similar using each of the three method. The sign does differ, however. 

```{r outcomes, results='hide'}
outcomes <- outcome_comparison(n, nobs, years, b0, b1, b2, b3, std_a, std_v, cellsize)
outcomes$plot
```

We now aggregate to the grid level. Above, we see the bias introduced by using different outcome variables. (Need a table here to show the different outcomes and will want to cite different papers that use these outcomes. Currently only two outcomes being used in this function)


```{r grids, results='hide'}
grid <- grid_sim(n, nobs, years, b0, b1, b2, b3, std_a, std_v, cellsize)
grid$plot
```


Using the outcome from above with the smallest amount of bias, we again look at the grid level aggregation to assess this outcome. 



```{r weighting, results='hide'}
weighting <- weightedreg_test(n, nobs, years, b0, b1, b2, b3, std_a, std_v, std_p, cellsize, ppoints)
weighting$plot
```

We now aggregate to the property level to determine whether weighting the regressions by property area is preferable. Clearly, weighting by property area leads to less bias in the estimates. Moving forward, we weight all regressions by area.  


```{r property_perturbations, results='hide'}
perturb <- property_perturb(n, nobs, years, b0, b1, b2, b3, std_a, std_v, std_p, cellsize, ppoints)
perturb$plot
```

In order to compare property level and grid level aggregation, we introduce perturbations at the property level to see if this induces any differences. It appears that when property level perturbations are introduced, aggregating to the property level and using property level fixed effects rather than doing so at the grid level may improve the estimates.

What is now interesting is that we seem to be identifying the ATT rather than the DID estimand that would be expected. In either case, aggregating to properties results in less bias relative to either teh DID or ATT parameters. In order to see if this is an anomaly, I alter the starting parameters 


```{r parameters_secondary}
b0 = .05
b1 = 0.2
b2 = -0.1
b3 = -.16
std_a = .1
std_v = 0.25
years = 3
nobs = 10000
n = 100


cellsize = 20
ppoints = 200
std_p = .2
```


```{r property_perturbations_2, results='hide'}
perturb2 <- property_perturb(n, nobs, years, b0, b1, b2, b3, std_a, std_v, std_p, cellsize, ppoints)
perturb2$plot
```

It seems that the property level aggregation does a better job of identifying the DID estimand here. The magnitude of the bias relative to the ATT is similar, however. 
