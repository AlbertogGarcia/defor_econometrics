---
title: "outline_sep19"
author: "Alberto Garcia"
date: "September 3, 2019"
updated: "September 24, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#binary fcns
source('quickmontey.R')
source('binary_coeffdist_fcn.R')
source('funcform.R')

#aggregated fcns
source('grid_scapegen.R')
source('outcome_comparison.R')
source('county_scapegen.R')
source('county_sims.R')
source('clustercover.R')
source('weightingarea.R')

```

Define universal parameters
```{r parameters}
set.seed(930)
b0 = .05
b1 = -0.1
b2 = -0.2
b3 = .16
std_a = .1
std_v = 0.25
years = 3
nobs = 10000
n = 30


cellsize = 15
ppoints = 75
std_p = .2

cpoints = 20
```



```{r DIDy, results='hide'}
DID_y <- quickmontey(n, nobs, years, b0, b1, b2, b3, std_a, std_v, "y")
DID_y$plot
```

Above, we allow the outcome to vary between 0 and 1 across time periods. We see a slight bias in the DID estimates of the ATT. This result stems from the fact that the DID estimand does not identify the ATT with the given DGP. 




```{r DIDy_it, results='hide'}
DID_yit <- quickmontey(n, nobs, years, b0, b1, b2, b3, std_a, std_v, "y_it")
DID_yit$plot
```

In the above plot, we drop pixels in the periods after they first become deforested. The DID estimates are still biased here. It appears that neither the sign nor magnitude of the bias seems to change, while the bias worsens slightly. 


```{r FE, results='hide'}
twowayFE <- binary_coeffdist_fcn(n, nobs, years, b0, b1, b2, b3, std_a, std_v)
twowayFE$plot
```

Above, we address the use of two-way fixed effects and the dropping of observations in the periods after pixels are first observed as deforested. The magnitude of the bias is smallest using the basic DID. The bias is negative when using the 2way FE dropping deforested obs and when using either the DID or 2way FE keeping obs. Note that the DID and 2way fixed effects estimates are identical when observations are not dropped. As we show in our proof, in the general case, using 2 way fixed effects dropping the observations yields the ATT plus the difference between the treated and untreated groups. The DID on the other hand should identify the ATT. 




```{r functionalforms, results='hide'}
functionalform <- funcform(n, nobs, years, b0, b1, b2, b3, std_a, std_v)
functionalform$plot
```

The above plot shows the DID bias depending on functional form decisions. Interestingly in our case, the magnitude of the bias is similar using each of the three method. The sign does differ, however. 

```{r outcomes, results='hide'}
outcomes <- outcome_comparison(n, nobs, years, b0, b1, b2, b3, std_a, std_v, cellsize)
outcomes$plot
```

We now aggregate to the grid level. Above, we see the bias introduced by using different outcome variables. (Need a table here to show the different outcomes and will want to cite different papers that use these outcomes. Currently only two outcomes being used in this function)

 


```{r aggregate, results = 'hide', warning=FALSE}
countycoverage <- clustercover(n, nobs, years, b0, b1, b2, b3, std_a, std_v, std_p, cellsize, ppoints, cpoints)
countycoverage$plot
```

This function includes three possible aggregation methods: county, property, and grid level. We then compute the coverage propability of the ATT with a 95% CI. We first cluster standard errors at the group level and then, simply use White standard errors for comparison. 

```{r coverages}

#coverages by aggregation nmethod
print(countycoverage$grid_clustercover)
print(countycoverage$prop_clustercover)
print(countycoverage$county_clustercover)
print(countycoverage$grid_cover)
print(countycoverage$prop_cover)
print(countycoverage$county_cover)

```

The property level aggregation leads to the least bias in this case. It also results in the expected coverage, while the county and grid level aggregation results in under coverage. It is unclear how much of the issue is related to the bias and not the standard errors themselves. The coverage seems to be the same whether we cluster the standard errors at the group level or simply use White standard errors. 



```{r weighting, results='hide', warning=FALSE}
weighting <- weightingarea(n, nobs, years, b0, b1, b2, b3, std_a, std_v, std_p, cellsize, ppoints, cpoints)
weighting$plot
```

Interestingly, we note that upon weighting the regression aggregated to the property level, the distribution is significantly wider. This also appears to happen with the regression aggregated to the county level, but not nearly to the same extent. 

As far as bias, weighting the regression aggregated to the grid level has almost no impact. This makes intuitive sense, since the grids are all of equal size. Weighting the property and county aggregated regressions results in less bias. We see a larger impact of weighting the regressions in these two cases, because there is more area heterogeneity across units. 





Next we'd like to incorporate the spatial and temporal autocorrelation. 