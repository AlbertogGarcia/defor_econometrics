---
title: "deforestation econometrics data generating process"
#author: "Alberto Garcia"
output:
  pdf_document:
    number_sections: yes
    toc: no
fontsize: 11pt    
documentclass: article
geometry: margin=1in
header-includes: 
  \usepackage{sectsty}
  \usepackage{enumitem}
  \usepackage{comment}
  \usepackage{multirow,array}
  \usepackage{makecell}
  \usepackage{amsmath}
  \usepackage{amsfonts} 
  \usepackage{amssymb} 
  \usepackage{graphicx} 
  \usepackage{float} 
  \usepackage{bbm} 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
# plots
source('did_trends.R')

#binary fcns
source('quickmonte.R')
source('TWFE_fcn.R')
source('DID_keep.R')
source('functionalform.R')
source('functionalform_agg.R')

source('outcome_fcn.R')
source('aggregation_fcn.R')
#source('pixelcluster_fcn.R')

source('vary_outcome_defor.R')
source('vary_outcome_yr.R')
source('vary_rate_funcform.R')
source('vary_rate_funcform_agg.R')

```

# DGP 

In order to enforce parallel trends, I allow the treated and untreated group to have different $\beta_2$ parameters. This gives enough flexibility to make sure that each group's $\beta_2 (t \ge t_{0})$ parameter results in a trend that would be the same in the absence of treatment. It appears that all of the major conclusions from the paper carry over to this framewok (dropping obs, TWFE, etc. ), while eliminating the intial bias in the case where the binary outcome can vary between 0 and 1 across periods

## altered text for draft

We employ a series of Monte Carlo simulations to (1) generate synthetic landscapes with known policy effectiveness and (2) analyze the performance of different econometric models in estimating the policy's known impact. Our landscape consists of administrative units that are either untreated $(D=0)$ or are assigned to a conservation treatment $(D=1)$. We observe deforestation in two, even-length periods, a pre-treatment $(t < t_{0})$ and a post-treatment $(t \ge t_{0})$ period. 

The data generating process underlying our Monte Carlo simulations begins with the assignment of five parameters: The mean, pre-treatment period deforestation rate for untreated units, $baseline_0$; the mean, pre-treatment period deforestation rate for treated units, $baseline_1$; untreated units' mean change in deforestation rates occurring between the pre- and post-treatment periods, $trend_0$; treated units' mean counterfactual change in deforestation rates occurring between the pre- and post-treatment periods in the absence of treatment, $trend_1$; and lastly, the average treatment effect of the policy on the treated units, $ATT$. The researcher's primary goal is to estimate ATT. We define the five parameters as follows:

\begin{align*}
baseline_0 &= E[y_{it}(0) |  t<t_0, D_i=0]\\
baseline_1 &= E[y_{it}(0) |  t<t_0, D_i=1]\\
trend_0 &= E[y_{it}(0) |  t\geq t_0, D_i=0] - E[y_{it}(0) |  t<t_0, D_i=0]\\
trend_1 &= E[y_{it}(0) |  t\geq t_0, D_i=1] - E[y_{it}(0) |  t<t_0, D_i=1]\\
ATT &= E[y_{it}(1) - y_{it}(0) |  t\geq t_0, D_i=1]\\
\end{align*}
<!-- Not needed in draft text -->

In all  of our simulations, we impose parallel trends (ie. set $trend_0 = trend_1$). 

Rather than directly observing each pixel's deforestation in each time period, the researcher observes annualized maps depicting pixel-level, binary deforestation $(y_{ivt}\ \epsilon \ 0, 1)$. We follow [@kerr; @pfaff2004] and model these binary deforestation events as a function of each pixel's unobservable value along a continuous, latent variable $(y^*_{ivt})$ indicating the utility of deforesting pixel $i$, in property $v$, in year $t$. We define this latent variable as:

$$y^*_{ivt} = \beta_0 + \beta_1 \mathbbm{1}\{  D_i = 1  \} +$$ 
$$\beta_{2,0} \mathbbm{1}\{  t \geq t_0  \} (1 - \mathbbm{1}\{  D_i = 1  \})+\beta_{2,1} \mathbbm{1}\{  t \geq t_0  \} \mathbbm{1}\{  D_i = 1  \} +$$
$$\beta_3 \mathbbm{1}\{  D_i = 1  \} \mathbbm{1}\{  t \geq t_0  \} + \alpha_i + u_{it} + \rho_{v}$$

The $\beta$ coefficients dictate how the utility of deforestation evolves over the two time periods $(\mathbbm{1}\{  t \geq t_0  \})$, across the control and treated units $(\mathbbm{1}\{  D_i = 1  \})$. These coefficients can be defined as a transformation of the five parameters assigned by the researcher ($baseline_0$, $baseline_1$, $trend_0$, $trend_1$, $ATT$; derivation provided in Appendix 1). In addition, we assume that the value of deforestation is influenced by time-invariant random disturbances at the scale of individual pixels ($\alpha_i \sim N(0, \sigma_a^2)$) or properties ($\rho_v \sim N(0, \sigma_p^2)$), as well as time-varying, pixel-scale disturbances ($u_{it} \sim N(0, \sigma_u^2)$). These disturbances can represent a variety of spatial and temporal processes including, for example, the biophysical characteristics of a location, or the preferences of a property owner. 

We assume that pixels with a positive utility of deforestation are cleared, resulting in the following mapping from the latent $y^*_{ivt}$ to the observed $y_{ivt}$ variable:
\begin{align}
 y_{ivt} = \begin{cases} 
      1 & y^*_{ivt} > 0  \\
      0 & otherwise
   \end{cases}
\end{align}

Here, the observed outcome variable, $y_{it}$, is equal to 1 if pixel $i$ is observed as deforested in time $t$ and 0 otherwise. The observed variable is the binary outcome visible to the researcher, which represents the result of a more complex data generating process that reflects the pre-defined effectiveness of the policy $(ATT)$ as well as temporal trends in deforestation $(trend)$, pre-treatment differences in deforestation probabilities $(baseline_1)$, unobservable, pixel-specific determinants of deforestation $(\alpha_i)$ and time-varying, pixel-level disturbances $(u_{it})$. 

## Example 1

Here are some examples of our simulations to show that this gives generally unbiased or expected results when we impose common trends. Here, we set:
\begin{align*}
baseline_0 &= 0.02\\
baseline_1 &= 0.05\\
trend_0 &= -0.005\\
trend_1 &= -0.005\\
ATT &= -0.01
\end{align*}



```{r generating beta parameters, results='hide'}

base_0 = .02
base_1 = .05
trend = -.005
ATT = -.01

std_a = 0.1
std_v = 0.25
years = 3
nobs = 10000
n = 200

cellsize = 10
ppoints = 50
std_p = 0
cpoints = 20

std_avp = (std_a^2+std_v^2+std_p^2)^.5
b0 = qnorm(base_0, mean = 0, sd = std_avp)
b1 = qnorm(base_1, mean = 0, sd = std_avp) - b0
b2_0 = qnorm(trend + base_0, mean = 0, sd = std_avp) - b0
b2_1 = qnorm(trend + base_1, mean = 0, sd = std_avp) - b0 - b1
b3 = qnorm( pnorm(b0+b1+b2_1, mean = 0, sd = std_avp) + ATT , mean = 0, sd = std_avp) - (b0 + b1 + b2_1)

```

```{r did trends, results='hide'}

# trends <- did_trends(years, b0, b1, b2_0, b2_1, b3, std_a, std_v)
# 
# trends$plot
# 
# ggsave(path = "figs", filename = "trends.png", dpi = 500)

# landscape_period2
# ggsave(path = "figs", filename = "landscape_2period.png", dpi = 500)

```

### DID allowing outcome to vary between 0 and 1 across periods

```{r did y, results='hide'}

DID_y <- quickmonte(n, nobs, years, b0, b1, b2_0, b2_1, b3, std_a, std_v, "y")

DID_y$plot

ggsave(path = "figs", filename = "did_y.png", dpi = 500)

```

```{r did yit, results='hide'}

DID_yit <- quickmonte(n, nobs, years, b0, b1, b2_0, b2_1, b3, std_a, std_v, "y_it")

DID_yit$plot

#ggsave(path = "figs", filename = "did_yit.png", dpi = 500)

```


```{r did defor, results='hide'}

DID_defor <- quickmonte(n, nobs, years, b0, b1, b2_0, b2_1, b3, std_a, std_v, "defor")

DID_defor$plot

#ggsave(path = "figs", filename = "did_defor.png", dpi = 500)

```

```{r functionalform 1, results='hide'}


func <- functionalform(n, nobs, years, b0, b1, b2_0, b2_1, b3, std_a, std_v)

func$plot

ggsave(path = "figs", filename = "func1.png", dpi = 500)

```

```{r functionalform  agg, results='hide'}


func_agg <- functionalform_agg(n, nobs, years, b0, b1, b2_0, b2_1, b3, std_a, std_v, cellsize)

func_agg$plot

ggsave(path = "figs", filename = "func_agg.png", dpi = 500)

```

```{r TWFE, results='hide'}

twoway <- TWFE_fcn(n, nobs, years, b0, b1, b2_0, b2_1, b3, std_a, std_v)

twoway$plot

ggsave(path = "figs", filename = "twoway.png", dpi = 500)

```

```{r did keep and drop, results='hide'}

did_keep <- DID_keep(n, nobs, years, b0, b1, b2_0, b2_1, b3, std_a, std_v)

did_keep$plot

ggsave(path = "figs", filename = "DID_keep.png", dpi = 500)

```

```{r functionalform 1, results='hide'}

outcome <- outcome_fcn(n, nobs, years, b0, b1, b2_0, b2_1, b3, std_a, std_v, cellsize)

outcome$plot

ggsave(path = "figs", filename = "outcome.png", dpi = 500)

```

```{r aggregate, results = 'hide', warning=FALSE}
aggregation <- aggregation_fcn(n, nobs, years, b0, b1, b2_0, b2_1, b3, std_a, std_v, std_p, cellsize, ppoints, cpoints)
#aggregation$plot

#ggsave(path = "figs", filename = "aggregation.png", dpi = 500)

#agg_biases <- aggregation$biases
#write.csv(agg_biases, "agg_biases.csv")


coverages_df <- aggregation$coverages_df
write.csv(coverages_df, "coverages.csv")

```



```{r varying func, results = 'hide', warning=FALSE}
# ATT_start = ATT
# base_0_start = base_0
# base_1_start = base_1
# trend_start = trend
# 
# vary_func <- vary_rate_funcform(60, nobs, years, base_0_start, base_1_start, trend_start, ATT_start, std_a, std_v )
# vary_func$plot
# ggsave(path = "figs", filename = "vary_func.png", dpi = 500)

```

```{r varying func poisson, results = 'hide', warning=FALSE}
ATT_start = ATT
base_0_start = base_0
base_1_start = base_1
trend_start = trend

vary_func_agg <- vary_rate_funcform_agg(60, nobs, years, base_0_start, base_1_start, trend_start, ATT_start, std_a, std_v, cellsize)
vary_func_agg$plot
ggsave(path = "figs", filename = "vary_func_agg.png", dpi = 500)

```

```{r aggregate p_err5, results = 'hide', warning=FALSE}
std_p = 0.05
std_avp = (std_a^2+std_v^2+std_p^2)^.5
b0 = qnorm(base_0, mean = 0, sd = std_avp)
b1 = qnorm(base_1, mean = 0, sd = std_avp) - b0
b2_0 = qnorm(trend + base_0, mean = 0, sd = std_avp) - b0
b2_1 = qnorm(trend + base_1, mean = 0, sd = std_avp) - b0 - b1
b3 = qnorm( pnorm(b0+b1+b2_1, mean = 0, sd = std_avp) + ATT , mean = 0, sd = std_avp) - (b0 + b1 + b2_1)

aggregation_5 <- aggregation_fcn(n, nobs, years, b0, b1, b2_0, b2_1, b3, std_a, std_v, std_p, cellsize, ppoints, cpoints)
#aggregation_5$plot
#ggsave(path = "figs", filename = "aggregation.png", dpi = 500)

agg_biases_5 <- aggregation_5$biases
#write.csv(agg_biases_5, "agg_biases_5.csv")

coverages5 <- aggregation_5$coverages_df
#write.csv(coverages5, "coverages_p5.csv")

```

```{r aggregate p_err15, results = 'hide', warning=FALSE}
std_p = 0.15
std_avp = (std_a^2+std_v^2+std_p^2)^.5
b0 = qnorm(base_0, mean = 0, sd = std_avp)
b1 = qnorm(base_1, mean = 0, sd = std_avp) - b0
b2_0 = qnorm(trend + base_0, mean = 0, sd = std_avp) - b0
b2_1 = qnorm(trend + base_1, mean = 0, sd = std_avp) - b0 - b1
b3 = qnorm( pnorm(b0+b1+b2_1, mean = 0, sd = std_avp) + ATT , mean = 0, sd = std_avp) - (b0 + b1 + b2_1)

aggregation_15 <- aggregation_fcn(n, nobs, years, b0, b1, b2_0, b2_1, b3, std_a, std_v, std_p, cellsize, ppoints, cpoints)
#aggregation_5$plot
#ggsave(path = "figs", filename = "aggregation.png", dpi = 500)

agg_biases_15 <- aggregation_15$biases
#write.csv(agg_biases_15, "agg_biases_15.csv")

coverages15 <- aggregation_15$coverages_df
write.csv(coverages15, "coverages_p15.csv")

```


```{r aggregate p_err25, results = 'hide', warning=FALSE}
std_p = 0.25
std_avp = (std_a^2+std_v^2+std_p^2)^.5
b0 = qnorm(base_0, mean = 0, sd = std_avp)
b1 = qnorm(base_1, mean = 0, sd = std_avp) - b0
b2_0 = qnorm(trend + base_0, mean = 0, sd = std_avp) - b0
b2_1 = qnorm(trend + base_1, mean = 0, sd = std_avp) - b0 - b1
b3 = qnorm( pnorm(b0+b1+b2_1, mean = 0, sd = std_avp) + ATT , mean = 0, sd = std_avp) - (b0 + b1 + b2_1)

aggregation_25 <- aggregation_fcn(n, nobs, years, b0, b1, b2_0, b2_1, b3, std_a, std_v, std_p, cellsize, ppoints, cpoints)
# aggregation_25$plot

agg_biases_25 <- aggregation_25$biases
# write.csv(agg_biases_25, "agg_biases_25.csv")

coverages25 <- aggregation_25$coverages_df
write.csv(coverages25, "coverages_p25.csv")

# pixelcounty_25 <- pixelcluster_fcn(100, nobs, years, b0, b1, b2_0, b2_1, b3, std_a, std_v, std_p, cellsize, ppoints, cpoints)
# 
# cover_pixelcounty_25 <- pixelcounty_25$covermat

```

```{r agg bias and rmse, results = 'hide', warning=FALSE}

# creating RMSE csv
RMSE <- function (x) sqrt(mean((x-0)^2))
rmse_p <- data.frame(
  "0" = unlist(lapply(agg_biases, FUN = RMSE)),
  "0.05" = unlist(lapply(agg_biases_5, FUN = RMSE)),
  "0.15" = unlist(lapply(agg_biases_15, FUN = RMSE)),
  "0.25" = unlist(lapply(agg_biases_25, FUN = RMSE))
  , check.names = FALSE
)
write.csv(rmse_p, "rmse_p.csv")

# creating bias csv
biases_p <- data.frame("0" = colMeans(agg_biases) , "0.05" = colMeans(agg_biases_5), "0.15" = colMeans(agg_biases_15), "0.25" = colMeans(agg_biases_25) ,check.names = FALSE)
write.csv(rmse_p, "bias_p.csv")

```

```{r plot rmse, results = 'hide', warning=FALSE}

rmse_plot_df <- rmse_p %>%
  rownames_to_column(var = "aggregation") %>%
  melt(variable.name = "sigma_p", value.name = "RMSE" )

plot_rmse = ggplot(data = rmse_plot_df, aes(x = as.numeric(as.character(sigma_p)), y = RMSE, colour = aggregation)) +
    geom_line(size = 1.2) +
  geom_hline(yintercept = 0, linetype = "dashed")+
    theme(plot.caption = element_text(hjust = 0.5))+
    labs(x= "standard error of property level disturbances")
plot_rmse

ggsave(path = "figs", filename = "rmse_p.png", dpi = 500)

bias_plot_df <- biases_p %>%
  rownames_to_column(var = "aggregation") %>%
  melt(variable.name = "sigma_p", value.name = "bias" )

plot_bias = ggplot(data = bias_plot_df, aes(x = as.numeric(as.character(sigma_p)), y = bias, colour = aggregation)) +
    geom_line(size = 1.2) +
  geom_hline(yintercept = 0, linetype = "dashed")+
    theme(plot.caption = element_text(hjust = 0.5))+
    labs(x= "standard error of property level disturbances")
plot_bias

ggsave(path = "figs", filename = "bias_p.png", dpi = 500)

```


```{r outcome by yr, results = 'hide', warning=FALSE}
base_0 = .02
base_1 = .05
trend = 0
ATT = 0
n = 50
years_min = 2
years_max = 8

yr_outcome1 <- vary_outcome_yr(n, nobs, years_min, years_max, ATT, trend, base_0, base_1, std_a, std_v, cellsize)
yr_outcome1$plot
ggsave(path = "figs", filename = "outcome_byyr1.png", dpi = 500)

yr_outcome2 <- vary_outcome_yr(n, nobs, years_min, years_max, ATT, trend, base_1, base_0, std_a, std_v, cellsize)
yr_outcome2$plot

ggsave(path = "figs", filename = "outcome_byyr2.png", dpi = 500)

```






## Example 2 (with lower deforestation rates; for outcome comparison and funcform)

Here are some examples of our simulations to show that this gives generally unbiased or expected results when we impose common trends. Here, we set:
\begin{align*}
baseline_0 &= 0.007\\
baseline_1 &= 0.01\\
trend_0 &= 0.002\\
trend_1 &= 0.002\\
ATT &= -0.004
\end{align*}



```{r generating beta parameters 3, results='hide'}

base_0 = .003
base_1 = .007
trend = -0.002
ATT = -.002

std_av = (std_a^2+std_v^2)^.5
b0 = qnorm(base_0, mean = 0, sd = std_av)
b1 = qnorm(base_1, mean = 0, sd = std_av) - b0
b2_0 = qnorm(trend + base_0, mean = 0, sd = std_av) - b0
b2_1 = qnorm(trend + base_1, mean = 0, sd = std_av) - b0 - b1
b3 = qnorm( pnorm(b0+b1+b2_1, mean = 0, sd = std_av) + ATT , mean = 0, sd = std_av) - (b0 + b1 + b2_1)

```



```{r did y 2, results='hide'}

func3 <- functionalform(n, nobs, years, b0, b1, b2_0, b2_1, b3, std_a, std_v)

func3$plot

```